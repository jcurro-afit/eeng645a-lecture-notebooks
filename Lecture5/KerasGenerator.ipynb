{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Generator\n",
    "In our previous example we made a generic generator in python. However we aren't interested in using fibonacci numbers to train ANNs we need real data usually stored on disk and not generated on the fly. So next we are going to go through the process of turning a csv file into a hdf5 file and making a generator to pull chunks from our new hdf5 file.\n",
    "\n",
    "So first the dataset which we will read in with Pandas (cause Pandas makes it easy to look at). The input features are some variables done to a plane simulation to alter magnetometer readings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosX</th>\n",
       "      <th>cosY</th>\n",
       "      <th>cosZ</th>\n",
       "      <th>flap angle(rad)</th>\n",
       "      <th>rudder angle(rad)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.364360</td>\n",
       "      <td>-0.23860</td>\n",
       "      <td>0.900170</td>\n",
       "      <td>0.783300</td>\n",
       "      <td>-0.29378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.516630</td>\n",
       "      <td>-0.56340</td>\n",
       "      <td>0.644730</td>\n",
       "      <td>0.343350</td>\n",
       "      <td>0.59530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.037998</td>\n",
       "      <td>-0.99223</td>\n",
       "      <td>-0.118450</td>\n",
       "      <td>0.588880</td>\n",
       "      <td>-0.46642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.629490</td>\n",
       "      <td>-0.18223</td>\n",
       "      <td>0.755340</td>\n",
       "      <td>-0.115410</td>\n",
       "      <td>-0.38319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.500480</td>\n",
       "      <td>0.11948</td>\n",
       "      <td>0.857470</td>\n",
       "      <td>-0.055621</td>\n",
       "      <td>0.52118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-0.139920</td>\n",
       "      <td>0.91155</td>\n",
       "      <td>0.386650</td>\n",
       "      <td>0.226880</td>\n",
       "      <td>0.33034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.577470</td>\n",
       "      <td>0.73689</td>\n",
       "      <td>-0.351450</td>\n",
       "      <td>-0.191640</td>\n",
       "      <td>0.68059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.087447</td>\n",
       "      <td>-0.93206</td>\n",
       "      <td>-0.351580</td>\n",
       "      <td>0.181340</td>\n",
       "      <td>-0.50669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.206470</td>\n",
       "      <td>0.97796</td>\n",
       "      <td>0.030993</td>\n",
       "      <td>-0.669570</td>\n",
       "      <td>0.13727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.248740</td>\n",
       "      <td>-0.36039</td>\n",
       "      <td>0.899030</td>\n",
       "      <td>-0.456660</td>\n",
       "      <td>0.71166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cosX     cosY      cosZ   flap angle(rad)   rudder angle(rad)\n",
       "0    -0.364360 -0.23860  0.900170          0.783300            -0.29378\n",
       "1    -0.516630 -0.56340  0.644730          0.343350             0.59530\n",
       "2    -0.037998 -0.99223 -0.118450          0.588880            -0.46642\n",
       "3     0.629490 -0.18223  0.755340         -0.115410            -0.38319\n",
       "4    -0.500480  0.11948  0.857470         -0.055621             0.52118\n",
       "...        ...      ...       ...               ...                 ...\n",
       "9995 -0.139920  0.91155  0.386650          0.226880             0.33034\n",
       "9996  0.577470  0.73689 -0.351450         -0.191640             0.68059\n",
       "9997  0.087447 -0.93206 -0.351580          0.181340            -0.50669\n",
       "9998  0.206470  0.97796  0.030993         -0.669570             0.13727\n",
       "9999  0.248740 -0.36039  0.899030         -0.456660             0.71166\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('/opt/data/MagData/EE699_IN.txt')\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out output target data is the magentic field reading of the magnetometer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Magnetic Field (nT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-112.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>844.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1851.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1279.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-246.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-703.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-871.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1929.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-932.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-935.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Magnetic Field (nT)\n",
       "0                 -112.69\n",
       "1                  844.88\n",
       "2                 1851.20\n",
       "3                -1279.80\n",
       "4                 -246.01\n",
       "...                   ...\n",
       "9995              -703.47\n",
       "9996              -871.67\n",
       "9997              1929.20\n",
       "9998              -932.63\n",
       "9999              -935.26\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.read_csv('/opt/data/MagData/EE699_Out.txt')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we would usually split the data into train, valid, test and preprocess it by normalization etc. but for right now we are only interested in making our generator so assume we do that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "# we did some preprocessing\n",
    "print(features.shape)\n",
    "print(features.values.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Made Dataset as HDF5\n",
    "Now we will take our data and store it to an `.h5` file which will make it much easier to work with on disk compared to the `.txt` files we read it from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/opt/data/MagData/EE699_dat.h5\"\n",
    "with h5py.File(filename, 'w') as h5file:\n",
    "    features_group = h5file.create_dataset(name='magdata/features', data=features)\n",
    "    output_group = h5file.create_dataset(name='magdata/output', data=output)\n",
    "    # h5file.create_dataset(name='test', data=np.arange(10))\n",
    "    features_group.attrs['Info'] = \"This is the input features for the magnetometer dataset\"\n",
    "    output_group.attrs['Info'] = \"This is the output targets for the magnetometer dataset\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.h5` files are broken into groups which can have subgroups. You can think of it like having folders with data in them. For example you could think of our data in a folder called `magdata` inside the file. You can also add attributed or metadata to the datasets. In this case I added some information to the groups which is pretty simple. The attributes are like dictionaries so they can take many types and not just strings.\n",
    "\n",
    "So now lets just for fun get our data back out from the file. First we will delete the old data to prove we are getting new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features does not exist\n"
     ]
    }
   ],
   "source": [
    "del features\n",
    "del output\n",
    "\n",
    "try:\n",
    "    print(features)\n",
    "except NameError:\n",
    "    print(\"features does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open our H5 file\n",
    "So now we will open the file and list the keys of the file which is like listing the folders/datasets on the root directory. Next we will pull out the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['magdata']>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(filename, 'r') as h5file:\n",
    "    print(h5file.keys()) # shows the 'folders' or 'datasets' in the file\n",
    "    magdata = h5file['magdata']\n",
    "    features = magdata['features'][...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now lets check if our features is intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36436 , -0.2386  ,  0.90017 ,  0.7833  , -0.29378 ],\n",
       "       [-0.51663 , -0.5634  ,  0.64473 ,  0.34335 ,  0.5953  ],\n",
       "       [-0.037998, -0.99223 , -0.11845 ,  0.58888 , -0.46642 ],\n",
       "       ...,\n",
       "       [ 0.087447, -0.93206 , -0.35158 ,  0.18134 , -0.50669 ],\n",
       "       [ 0.20647 ,  0.97796 ,  0.030993, -0.66957 ,  0.13727 ],\n",
       "       [ 0.24874 , -0.36039 ,  0.89903 , -0.45666 ,  0.71166 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise we actually have a `ndarray` now and not a pandas `DataFrame`. When we gave the data to the `create_dataset` function it converted our pandas `DataFrame` to a python `ndarray`. We could have explicitly given an `ndarray` but I wanted to emphasize the change with a surprise. If you really want to store the `DataFrame` object pandas has built in functions to do so.\n",
    "\n",
    "## The Actual Generator\n",
    "Anyway we didn't come here to store and read data (even though that may be useful for future reference) we actually want a generator. So lets do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HDF5Generator(hdf5_path,\n",
    "                  n_batches, \n",
    "                  hdf5XGroupName='train_set_x', \n",
    "                  hdf5YGroupName=\"train_set_y\",\n",
    "                  batch_size=100):\n",
    "    \"\"\" Makes a generator function that pulls random batches of data from and hdf5 file\n",
    "\n",
    "    :param hdf5_path: The path to the hdf5 file\n",
    "    :param n_batches: number of batches in the file\n",
    "    :param batch_size: the size of each batch\n",
    "    :param hdf5XGroupName: the path to the dataset for the features, X, or input data\n",
    "    :param hdf5YGroupName: the path to the dataset for the output targets\n",
    "\n",
    "    :return: a generator that yields batches of data from an hdf5 file\n",
    "    \"\"\"\n",
    "    trainIndices = list(range(n_batches))\n",
    "    with h5py.File(name=hdf5_path, mode='r') as f:\n",
    "        while True:\n",
    "            np.random.shuffle(trainIndices)\n",
    "            for batch_idx in trainIndices:\n",
    "                startIdx = batch_idx * batch_size\n",
    "                endIdx = (batch_idx + 1) * batch_size\n",
    "                trainXbatch = f[hdf5XGroupName][startIdx:endIdx]\n",
    "                trainYbatch = f[hdf5YGroupName][startIdx:endIdx]\n",
    "                yield (trainXbatch, trainYbatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah ok thats a lot of code lets break it up part by part. First the input.\n",
    "We can read the nice docstring to determine what all our inputs are doing. \n",
    "\n",
    "`hdf5_path` is the path to the hdf5 file that we saved earlier\n",
    "\n",
    "`n_batches` is the number of batches in the file and the size of each batch. This will be used to slice the dataset into non overlapping batches.\n",
    "\n",
    "actually lets just call this and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object HDF5Generator at 0x7f2ccf02c120>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = HDF5Generator(filename, \n",
    "                    n_batches=100, \n",
    "                    hdf5XGroupName='magdata/features', \n",
    "                    hdf5YGroupName='magdata/output', \n",
    "                    batch_size=100)\n",
    "gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go we have a generator called `gen`. What you don't believe me? You say the output just says generator object which is too generic to mean anything? fine lets call it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.25252  , -0.93161  , -0.26142  ,  0.39357  , -0.43605  ],\n",
       "        [-0.93147  , -0.35422  ,  0.082949 , -0.39371  , -0.68304  ],\n",
       "        [-0.65945  , -0.421    ,  0.62281  , -0.16878  ,  0.23097  ],\n",
       "        [-0.90437  ,  0.41962  , -0.077699 ,  0.1057   , -0.70672  ],\n",
       "        [-0.30324  , -0.78729  ,  0.53687  ,  0.74315  ,  0.23942  ],\n",
       "        [ 0.60058  ,  0.68253  , -0.41648  ,  0.6709   ,  0.22038  ],\n",
       "        [ 0.31358  , -0.62331  ,  0.71635  ,  0.46601  ,  0.23368  ],\n",
       "        [ 0.077513 , -0.99009  , -0.11708  , -0.46655  ,  0.079592 ],\n",
       "        [ 0.8654   , -0.22319  ,  0.44863  ,  0.073477 , -0.46992  ],\n",
       "        [-0.0084025, -0.83156  ,  0.55538  , -0.4282   ,  0.45822  ]]),\n",
       " array([[ 1566.6 ],\n",
       "        [ 1991.2 ],\n",
       "        [  896.24],\n",
       "        [ 1222.8 ],\n",
       "        [  968.02],\n",
       "        [ -776.7 ],\n",
       "        [ -337.93],\n",
       "        [ 1789.2 ],\n",
       "        [-1051.3 ],\n",
       "        [  581.32]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch_input, batch_output) = next(gen)\n",
    "batch_input[:10,:], batch_output[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(batch_input.shape)\n",
    "print(batch_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See I actually got a batch with 100 samples. What you don't believe that I can do it again? You say the file is closed and another call will crash it? OMG well here we go again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.22654  , -0.80547  ,  0.54763  ,  0.30697  ,  0.25748  ],\n",
       "        [-0.3039   ,  0.29177  ,  0.90693  ,  0.5679   ,  0.11319  ],\n",
       "        [ 0.24899  , -0.55194  ,  0.79584  ,  0.079616 , -0.56072  ],\n",
       "        [-0.5547   ,  0.54985  ,  0.62447  ,  0.66148  , -0.66118  ],\n",
       "        [-0.85404  , -0.46113  , -0.24079  , -0.68072  ,  0.0064763],\n",
       "        [ 0.5899   , -0.79136  , -0.16053  ,  0.72774  ,  0.045258 ],\n",
       "        [-0.17494  ,  0.73115  ,  0.6594   ,  0.57312  ,  0.39844  ],\n",
       "        [ 0.54991  , -0.58115  ,  0.59989  , -0.70943  ,  0.37904  ],\n",
       "        [-0.17393  , -0.90106  ,  0.3973   ,  0.25027  , -0.50694  ],\n",
       "        [-0.13397  , -0.94666  , -0.29307  ,  0.63367  , -0.31338  ]]),\n",
       " array([[ 270.11],\n",
       "        [-646.01],\n",
       "        [-458.53],\n",
       "        [-105.67],\n",
       "        [2492.7 ],\n",
       "        [ 734.65],\n",
       "        [-790.1 ],\n",
       "        [-583.42],\n",
       "        [1191.  ],\n",
       "        [2123.6 ]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch_input2, batch_output2) = next(gen)\n",
    "batch_input2[:10,:], batch_output2[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the file is still open in the generator and I can make consecutive calls to it. Also check out that I have different data and I didn't just reprint the same batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(batch_input, batch_input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(batch_output, batch_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to reiterate this may be a little over the top for a dataset with only 10,000 samples that was like under half a megabyte in RAM. However we might imagine a dataset that was very large say 100GB and that we could not fit at once in RAM (especially on a cheap laptop) and would need to process one batch at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
